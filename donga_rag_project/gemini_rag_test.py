import os
from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader # PDF ë¡œë” ì‚¬ìš©
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# --- 1. ì„¤ì • ---

# Gemini API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (ë°˜ë“œì‹œ ìì‹ ì˜ í‚¤ë¡œ êµì²´!)
os.environ["GOOGLE_API_KEY"] = "AIzaSyC3H_EHCl4lAEtmo-OmoJ1dooDWSD_xD5k"

# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜(donga_rag_project)ì—ì„œ í•œ ë‹¨ê³„ ìƒìœ„ í´ë”(Campus Finder)ë¥¼ ê°€ë¦¬í‚´
pdf_path = "../ë™ì•„ëŒ€í•™êµ _ ì „ê³µ ë§ˆì´í¬ë¡œëª¨ë“ˆì œ ì•ˆë‚´ _ êµê³¼ê³¼ì • _ í•™ì‚¬ì•ˆë‚´.pdf"

# --- 2. ë°ì´í„° ë¡œë”© (Load) ---

# PyPDFLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ PDF íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
print(f"'{pdf_path}' íŒŒì¼ ë¡œë”© ì‹œì‘...")
loader = PyPDFLoader(pdf_path)
documents = loader.load()
print(f"PDFì—ì„œ {len(documents)}ê°œ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

# --- 3. ë°ì´í„° ë¶„í•  (Split) ---

# ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œë¥¼ AIê°€ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í¬ê¸°ë¡œ ìë¦…ë‹ˆë‹¤.
print("ë°ì´í„° ë¶„í•  ì‹œì‘...")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
texts = text_splitter.split_documents(documents)
print(f"ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬ ê°œìˆ˜: {len(texts)}ê°œ")

# --- 4. ë°ì´í„° ì €ì¥ (Store) ---

# ë¶„í• ëœ í…ìŠ¤íŠ¸ë¥¼ Gemini ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•´ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ ,
# ChromaDB (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)ì— ì €ì¥í•©ë‹ˆë‹¤.
print("ì„ë² ë”© ë° ë²¡í„° ì €ì¥ ì‹œì‘...")
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = Chroma.from_documents(documents=texts, embedding=embeddings)
print("ë²¡í„° ì €ì¥ ì™„ë£Œ.")

# --- 5. RAG ì²´ì¸ ìƒì„± ---

# ë‹µë³€ ìƒì„±ì„ ìœ„í•œ Gemini LLMì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
llm = GoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)

# ë²¡í„° ì €ì¥ì†Œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ëŠ” ê²€ìƒ‰ê¸°(Retriever)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
retriever = vectorstore.as_retriever()

# ê²€ìƒ‰ëœ ì •ë³´(context)ì™€ ì§ˆë¬¸ì„ í•¨ê»˜ LLMì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” RAG ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤.
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

print("\nâœ… RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

# --- 6. ì§ˆë¬¸ ë° ë‹µë³€ (ë¬´í•œ ë°˜ë³µ) ---

while True:
    question = input("\n[ì§ˆë¬¸] (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
    if question.lower() == 'exit':
        print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
    
    # RAG ì²´ì¸ì„ ì‹¤í–‰í•˜ì—¬ ë‹µë³€ ìƒì„±
    result = qa_chain.invoke({"query": question})
    
    print(f"\n[ë‹µë³€] {result['result']}")
    
    # (ì„ íƒ ì‚¬í•­) ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ ì†ŒìŠ¤ ë¬¸ì„œì˜ ì¼ë¶€ë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
    # print("\n[ì°¸ê³  ì†ŒìŠ¤]")
    # for doc in result['source_documents']:
    #     print(f"ğŸ“„ í˜ì´ì§€ {doc.metadata.get('page', '?')}: '{doc.page_content[:150]}...'")